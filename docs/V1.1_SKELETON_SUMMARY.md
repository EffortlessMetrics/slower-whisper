# v1.1 Skeleton Implementation Summary

**Date:** 2025-11-17
**Status:** Contract-first skeleton complete ✅

---

## What Was Built

This document summarizes the v1.1 skeleton implementation for speaker diarization in slower-whisper.

### Core Philosophy

**Contract-First Design:** Build the API contracts, test structure, and documentation *before* touching pyannote.audio.

This approach:
- Flushes out schema/API design issues early
- Enables parallel work on docs, tests, and implementation
- Provides clear acceptance criteria before code is written
- Makes the roadmap feel executable, not aspirational

---

## Deliverables

### 1. API Skeleton Code ✅

**Files Created:**

- **`transcription/diarization.py`** (167 lines)
  - `SpeakerTurn` dataclass: Output of diarization model
  - `SpeakerInfo` dataclass: Global speaker metadata
  - `Diarizer` class: Diarization engine (raises NotImplementedError)
  - `assign_speakers_to_segments()`: Segment attribution function (raises NotImplementedError)
  - Full docstrings with implementation notes

- **`transcription/turns.py`** (127 lines)
  - `Turn` dataclass: Conversational turn structure
  - `build_turns()`: Turn grouping function (raises NotImplementedError)
  - `aggregate_turn_stats()`: Future v1.2 feature placeholder
  - Docstrings with v1.1/v1.2 scoping

**Files Modified:**

- **`transcription/models.py`**
  - Added `speakers: list[dict] | None` to Transcript
  - Added `turns: list[dict] | None` to Transcript
  - Updated docstrings with v1.1+ field semantics

- **`transcription/writers.py`**
  - `write_json()`: Serialize speakers/turns if present
  - `load_transcript_from_json()`: Load speakers/turns (graceful fallback)
  - Backward/forward compatibility maintained

- **`transcription/cli.py`**
  - Added `--enable-diarization` flag to `transcribe` subcommand
  - Added warning message for NOT IMPLEMENTED status
  - No crashes when flag is used

---

### 2. BDD Scenarios ✅

**File:** `tests/features/transcription.feature`

**Added 3 scenarios:**

1. **Transcripts have nullable speaker fields in v1.0/v1.1**
   - Validates schema v2 has `speaker` field on all segments
   - Checks speaker values are null or valid IDs

2. **Schema v2 supports speakers and turns arrays**
   - Validates optional `speakers` and `turns` arrays
   - Checks structure when present

3. **Speaker diarization flag shows not-implemented warning**
   - Tests `--enable-diarization` CLI behavior
   - Ensures graceful handling (no crash)
   - Validates speaker fields remain null

**Note:** Step definitions need implementation (tracked in GitHub issue #6).

---

### 3. Testing Strategy ✅

**File:** `docs/TESTING_STRATEGY.md`

**Added Section:** Layer 2: Speaker Diarization (v1.1+)

**Content:**
- Quality thresholds (DER < 0.25, speaker count accuracy > 80%)
- MVP testbed specification:
  - Synthetic 2-speaker test (12s, A-B-A-B pattern, DER = 0.00)
  - AMI Meeting Corpus subset (real-world, 5-10 excerpts)
- BDD scenarios for synthetic tests
- Benchmark script outline (`benchmarks/eval_diarization.py`)

---

### 4. Design Documentation ✅

**File:** `docs/SPEAKER_DIARIZATION.md` (450+ lines)

**Comprehensive design doc covering:**

1. **Overview:** What diarization does, design principles
2. **Architecture:** Components, data flow, caching strategy
3. **Schema Impact:** Before/after JSON examples, backward compatibility
4. **Implementation Plan:** 4-phase roadmap with acceptance criteria
5. **MVP Testbed:** Synthetic 2-speaker spec, AMI dataset selection
6. **Configuration:** CLI flags, config fields, usage examples
7. **Performance Expectations:** Processing speed, memory, end-to-end timing
8. **Error Handling:** Graceful degradation policy
9. **Future Enhancements:** v1.2 and v2.0 roadmap
10. **Testing Checklist:** Pre-release validation steps

**This is the "single source of truth" for v1.1 speaker work.**

---

### 5. GitHub Issue Templates ✅

**File:** `docs/V1.1_GITHUB_ISSUES.md`

**9 issues defined:**

**Required for v1.1 (blocking):**
1. Implement pyannote.audio integration
2. Implement speaker-to-segment assignment
3. Implement basic turn building
4. Wire diarization into pipeline
5. Generate synthetic 2-speaker test audio
6. Add BDD step definitions
7. Update documentation

**Optional for v1.1:**
8. Per-speaker prosody baselines (defer to v1.2 if needed)

**Future (v1.2):**
9. AMI dataset evaluation benchmark

Each issue has:
- Clear description
- Acceptance criteria (checkboxes)
- Related files
- References to design docs
- Labels and milestone

---

## Validation

### Code Quality ✅

```bash
# Imports work
uv run python -c "from transcription.diarization import Diarizer; ..."
# ✓ Imports successful

# Instantiation works
uv run python -c "from transcription.diarization import Diarizer; d = Diarizer(); ..."
# ✓ Diarizer instantiated: device=auto, min_speakers=None

# CLI flag exists
uv run slower-whisper transcribe --help | grep "enable-diarization"
# --enable-diarization, --no-enable-diarization

# Code formatting
uv run ruff format transcription/diarization.py transcription/turns.py ...
# 5 files left unchanged

# Linting
uv run ruff check transcription/diarization.py transcription/turns.py ...
# All checks passed!
```

### Schema Compatibility ✅

- v1.0 transcripts load into v1.1 code (speakers/turns default to null)
- v1.1 transcripts (with speakers/turns) write correctly
- No schema version bump required (optional fields)
- Forward/backward compatibility maintained

---

## What's Next

### Immediate (Before Implementation)

1. **Create GitHub issues** from `docs/V1.1_GITHUB_ISSUES.md`
   - Copy each issue template into GitHub
   - Set labels, milestone (v1.1.0)
   - Assign or leave unassigned

2. **Generate synthetic 2-speaker audio** (Issue #5)
   - Script: `tests/fixtures/generate_synthetic_2speaker.py`
   - TTS-based with distinct voices
   - 12s, A-B-A-B pattern
   - This anchors all BDD tests

3. **Implement BDD step definitions** (Issue #6)
   - Add steps to `tests/steps/test_transcription.py`
   - Validate scenarios pass (speaker = null case)

### Phase 2: pyannote Integration (2-3 weeks)

Start with **Issue #1** (pyannote integration):

1. Add `pyannote.audio>=3.1.0` to `[diarization]` extra in `pyproject.toml`
2. Implement `Diarizer.run()`:
   - Load pyannote pipeline (lazy init)
   - GPU/CPU device selection
   - Convert output to `List[SpeakerTurn]`
3. Test on synthetic 2-speaker audio
4. Iterate until DER = 0.00 on synthetic

Then **Issue #2** (speaker assignment):

1. Implement overlap-based assignment
2. Build `SpeakerInfo` aggregates
3. Test on synthetic data
4. Validate speaker fields populate correctly

### Phase 3: Turn Building (1 week)

**Issue #3:**

1. Implement `build_turns()` basic grouping
2. Test A-B-A-B pattern recognition
3. Wire into pipeline after speaker assignment

### Phase 4: Integration & Testing (1 week)

**Issue #4:**

1. Wire diarization into `transcribe_directory()`
2. End-to-end CLI test
3. Graceful degradation on errors

### Phase 5: Documentation & Release (1 week)

**Issue #8:**

1. Update README, ARCHITECTURE, CLAUDE.md
2. Add example JSON outputs
3. Update CHANGELOG
4. Release v1.1.0

---

## Design Decisions Locked In

These are now **contracts** and should not change without discussion:

1. **Schema v2 stability:**
   - Core fields (`file`, `language`, `segments.{id,start,end,text}`) are locked
   - `speakers` and `turns` are optional, null by default
   - No version bump for adding optional fields

2. **Speaker ID format:**
   - Canonical schema IDs: `"spk_0"`, `"spk_1"`, ... (normalized, backend-agnostic)
   - Raw backend IDs (e.g., pyannote's `"SPEAKER_00"`) are internal only
   - No speaker names (diarization only, not identification)

3. **Turn grouping logic:**
   - Contiguous segments with same speaker → one turn
   - Optional pause-based splitting (threshold configurable)
   - v1.1 provides basic structure; v1.2 adds rich metadata

4. **Error handling:**
   - Diarization failures never block transcription
   - Fallback to speaker = null
   - Log warnings, continue processing

5. **Caching:**
   - Diarization results cached by (audio hash, config, model version)
   - Separate cache file: `{basename}_diarization.json`

6. **Quality targets:**
   - DER < 0.25 on AMI subset (good enough for conversation intelligence)
   - Speaker count accuracy > 80%
   - Perfect on synthetic tests (DER = 0.00)

---

## Lessons from This Approach

**What worked:**

1. **Contract-first design flushes out issues early:**
   - Schema additions (speakers/turns) happened *before* implementation
   - API shape is now clear (no surprises during coding)

2. **Documentation forces clarity:**
   - Writing `SPEAKER_DIARIZATION.md` revealed caching strategy gaps
   - Testing strategy defined quality thresholds upfront

3. **BDD scenarios as acceptance tests:**
   - Each issue has clear "done" criteria
   - No ambiguity about what v1.1 means

**What to watch:**

1. **Synthetic tests may be too easy:**
   - TTS voices are very distinct
   - Real-world audio has noise, overlaps, similar voices
   - AMI dataset will be the real test

2. **pyannote.audio may have surprises:**
   - Model download flow
   - GPU memory issues
   - Inference speed variance

3. **Schema evolution:**
   - v1.1 adds speakers/turns (optional)
   - v1.2 may add turn metadata (questions, interruptions)
   - Need to define when v3 is required

---

## Timeline Estimate

**Conservative (Q1 2026 target):**

- Week 1-2: pyannote integration + speaker assignment
- Week 3: Turn building
- Week 4: Integration + synthetic tests
- Week 5: Real-world testing (AMI dataset)
- Week 6: Documentation + polish
- Week 7: Buffer for issues

**Optimistic (if pyannote "just works"):**

- Week 1: pyannote + assignment
- Week 2: Turns + integration
- Week 3: Testing + docs
- Week 4: Buffer

**Most likely: 5-7 weeks → late December 2025 / early January 2026**

---

## Success Criteria

v1.1.0 is **done** when:

- [ ] All 7 required GitHub issues closed
- [ ] BDD scenarios pass (synthetic 2-speaker, single-speaker, no-diarization)
- [ ] Synthetic 2-speaker test: DER = 0.00, 2 speakers, A-B-A-B
- [ ] CLI `--enable-diarization` works end-to-end
- [ ] Documentation updated (README, ARCHITECTURE, CHANGELOG)
- [ ] Code formatted, linted, type-checked
- [ ] Pre-commit hooks pass
- [ ] Docker smoke tests pass

**Bonus (nice-to-have):**
- [ ] AMI dataset DER < 0.25
- [ ] Per-speaker prosody baselines

---

## Questions or Next Steps?

- **Ready to code?** Start with Issue #5 (synthetic audio) or Issue #1 (pyannote)
- **Need discussion?** Open GitHub discussion for design questions
- **Found issues?** Update `SPEAKER_DIARIZATION.md` or issue templates

---

**Document History:**
- 2025-11-17: Initial skeleton implementation summary
